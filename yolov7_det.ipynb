{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "97cTz0E9z1cl",
        "oeB12ooFS8I6",
        "P3VHszC0iApH",
        "fxPT6Hs-mNKM",
        "zbUDjVABmTX_",
        "z983kByIiIJf",
        "DHgF8Lc2mdcC",
        "AxN38JzrmjbI",
        "uczClcx1hSyr",
        "G3TiROODJJAV",
        "kHpc32hVaJsi",
        "dqbk8aYMwQCE",
        "YI8ZRHY7wZxh",
        "kjEuFGsawe40",
        "G4gCVCD3k0c5",
        "FXalcrJCq4Lc",
        "y14NYRMUrIyT"
      ],
      "mount_file_id": "1CSsRjCSMiCeH-sywQsACuSeJEd6QBvQs",
      "authorship_tag": "ABX9TyNWXne4OmyqE8V5q9/NbUJm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M3liss/BA-Project---1st-draft/blob/main/yolov7_det.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Requirements\n",
        "\n",
        "There are a few requirements that need to be fulfilled before the the actual testing can start. Please make sure beforehand that you have added the repository to your google drive to save the different weights and models to your own directory.\n",
        "\n",
        "1. Change the resources to GPU for better training.\n",
        "2. Run the first cell to Install all requirements and git init to create an empty repository. Please note that you need to change the path to the requirements file to your own repository in google drive.\n",
        "3. Make sure that the train and test data is in /val and /train folders. \n",
        "4. Create a cfg/training/yolov7.yaml file. This file has can be templated from cfg/training/yolov7.yaml. It needs to have the correct number of classes, the correct labels and the correct folders for train and val.\n",
        "5. Add the images to test and val folders that you specified beforehand. If you have run the algorithm before and changed these folders, delete the cache folder. \n",
        "\n",
        "Make sure all of these steps are done before starting.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "97cTz0E9z1cl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfjNBIAF8sIc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2caf70a7-1698-4afa-b7fd-9d678a92a828"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.9/dist-packages (from -r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 4)) (3.7.1)\n",
            "Requirement already satisfied: numpy<1.24.0,>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from -r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 5)) (1.22.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.9/dist-packages (from -r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 6)) (4.7.0.72)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.9/dist-packages (from -r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 7)) (8.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.9/dist-packages (from -r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 8)) (6.0)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.9/dist-packages (from -r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 9)) (2.27.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from -r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 10)) (1.10.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from -r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 11)) (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision!=0.13.0,>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from -r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 12)) (0.15.1+cu118)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.9/dist-packages (from -r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 13)) (4.65.0)\n",
            "Requirement already satisfied: protobuf<4.21.3 in /usr/local/lib/python3.9/dist-packages (from -r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 14)) (3.20.3)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from -r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 17)) (2.12.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.9/dist-packages (from -r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 21)) (1.4.4)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from -r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 22)) (0.12.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.9/dist-packages (from -r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 34)) (7.34.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from -r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 35)) (5.9.4)\n",
            "Collecting thop\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 4)) (4.39.3)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 4)) (5.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 4)) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 4)) (1.4.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 4)) (1.0.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 4)) (23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 9)) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 9)) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 9)) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 9)) (2.0.12)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch!=1.12.0,>=1.7.0->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 11)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch!=1.12.0,>=1.7.0->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 11)) (3.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch!=1.12.0,>=1.7.0->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 11)) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch!=1.12.0,>=1.7.0->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 11)) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch!=1.12.0,>=1.7.0->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 11)) (3.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch!=1.12.0,>=1.7.0->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 11)) (3.1.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.7.0->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 11)) (16.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.7.0->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 11)) (3.25.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 17)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 17)) (1.53.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 17)) (67.6.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 17)) (0.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 17)) (3.4.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 17)) (2.17.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 17)) (1.0.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 17)) (1.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 17)) (0.40.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 17)) (2.2.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.1.4->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 21)) (2022.7.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.9/dist-packages (from ipython->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 34)) (2.14.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from ipython->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 34)) (4.4.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.9/dist-packages (from ipython->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 34)) (0.2.0)\n",
            "Collecting jedi>=0.16\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from ipython->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 34)) (3.0.38)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.9/dist-packages (from ipython->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 34)) (0.1.6)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/dist-packages (from ipython->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 34)) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.9/dist-packages (from ipython->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 34)) (5.7.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.9/dist-packages (from ipython->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 34)) (4.8.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 17)) (4.9)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 17)) (1.16.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 17)) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 17)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.4.1->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 17)) (1.3.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib>=3.2.2->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 4)) (3.15.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from jedi>=0.16->ipython->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 34)) (0.8.3)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 17)) (6.1.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/dist-packages (from pexpect>4.3->ipython->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 34)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 34)) (0.2.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 17)) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch!=1.12.0,>=1.7.0->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 17)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.4.1->-r /content/drive/MyDrive/BA/yolov7-main/requirements.txt (line 17)) (3.2.2)\n",
            "Installing collected packages: jedi, thop\n",
            "Successfully installed jedi-0.18.2 thop-0.1.1.post2209072238\n",
            "Initialized empty Git repository in /content/.git/\n"
          ]
        }
      ],
      "source": [
        "!pip install -r /content/drive/MyDrive/BA/yolov7-main/requirements.txt\n",
        "! git init"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# move into directory\n",
        "%cd /content/drive/MyDrive/BA/yolov7-main\n",
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "TMclL1iGhvB5",
        "outputId": "be45d62e-e1e1-464c-a7f8-cb3f275fed75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/BA/yolov7-main\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/BA/yolov7-main'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training\n",
        "\n",
        "There are three different datasets as mentioned in the project's thesis. The first one with 50 images, the second with 100 and the third with 240. All of their datasets can be found in the repository. If trained again, they should have the same results.\n",
        "\n",
        "The process of training is simple. Run the commands and see the training process yourself.\n",
        "\n",
        "How to train:\n",
        "1. Go into your repository in google drive.\n",
        "2. Change the --name to got o the repository specified\n",
        "3. Change the --weights to the ones you want\n",
        "4. Specify --data to where you have specified the number of classes, the instances of classes and the train and val folder (here: coco.yaml)\n",
        "5. Specify --hyp to go to the data/50_images.yaml file. Again, this is giving hyp parameters needed.\n",
        "6. Specify --cfg. This has the CNN head and neck saved and needs to be changed.\n",
        "7. always delete data/train.cache if the train data was changed.\n",
        "\n",
        "After training, each best.pt can be found in runs under their respective folders /weights/best.pt. To see the results, open up the results.png to compare. These results are only according to the training part and not for actual deployment.\n"
      ],
      "metadata": {
        "id": "MHNwPWkCarVG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training with 50 images"
      ],
      "metadata": {
        "id": "54J8gJZnhYtH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training with normal dataset.\n",
        "\n",
        "This training trains with the pretrained model from the COCO dataset with the first dataset. After running it with 35 epochs, the best weights are under: best_50.pt\n",
        "\n",
        "\n",
        "Results: \n",
        "*   Time: 5 minutes\n",
        "*   \n",
        "\n",
        "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:02<00:00,  2.12s/it]\n",
        "                 all          30          52       0.507       0.664       0.642       0.248\n",
        "                ball          30          25       0.593        0.92       0.877       0.398\n",
        "                hand          30          27       0.421       0.407       0.407      0.0975"
      ],
      "metadata": {
        "id": "utZih58fQW1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --workers 8 --device 0 --batch-size 15 --epochs 35 --img 640 640 --hyp data/50_images.yaml --name 50_img --weights 'yolov7_training.pt' --cfg cfg/training/yolov7.yaml"
      ],
      "metadata": {
        "id": "U3oQag6QQgF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training with augmented dataset\n",
        "\n",
        "This training trains with the pretrained model from the COCO dataset with the first dataset and augmented data. After running it for 35 epochs, the best weights are saved under best_50AUG.pt.\n",
        "\n",
        "Results: \n",
        "*   Time: 10 minutes\n",
        "\n",
        "*   Accuracy (mAP):\n",
        "\n",
        "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.40it/s]\n",
        "                 all          30          52       0.846       0.924       0.951       0.534\n",
        "                ball          30          25       0.807           1       0.967       0.548\n",
        "                hand          30          27       0.884       0.848       0.934       0.521"
      ],
      "metadata": {
        "id": "oeB12ooFS8I6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --workers 8 --device 0 --batch-size 15 --epochs 40 --img 640 640 --hyp data/50_images.yaml --name 50_img_AUG --weights 'yolov7_training.pt' --cfg cfg/training/yolov7.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJPpn8mITCkL",
        "outputId": "71e75dcb-96ff-453d-ed6d-98b641e33616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOR 🚀 2023-2-9 torch 1.13.1+cu116 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=15, bbox_interval=-1, bucket='', cache_images=False, cfg='cfg/training/yolov7.yaml', data='data/coco.yaml', device='0', entity=None, epochs=40, evolve=False, exist_ok=False, freeze=[0], global_rank=-1, hyp='data/50_images.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='50_img_AUG', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/50_img_AUG', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=15, upload_dataset=False, v5_metric=False, weights='yolov7_training.pt', workers=8, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "2023-03-01 22:42:46.403614: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-01 22:42:48.295002: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2023-03-01 22:42:48.295168: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2023-03-01 22:42:48.295191: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mtrain=data/50_images/train, val=data/50_images/val, nc=2, names=['ball', 'hand'], lr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, paste_in=0.0, loss_ota=1\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 12                -1  1         0  models.common.MP                        []                            \n",
            " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
            " 25                -1  1         0  models.common.MP                        []                            \n",
            " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 38                -1  1         0  models.common.MP                        []                            \n",
            " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
            " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
            " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 76                -1  1         0  models.common.MP                        []                            \n",
            " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
            " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 89                -1  1         0  models.common.MP                        []                            \n",
            " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
            " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
            " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
            "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
            "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
            "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
            "105   [102, 103, 104]  1     39550  models.yolo.IDetect                     [2, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 415 layers, 37201950 parameters, 37201950 gradients, 105.1 GFLOPS\n",
            "\n",
            "Transferred 555/566 items from yolov7_training.pt\n",
            "Scaled weight_decay = 0.00046875\n",
            "Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'data/train' images and labels... 98 found, 2 missing, 0 empty, 0 corrupted: 100% 100/100 [00:00<00:00, 120.51it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: data/train.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'data/val' images and labels... 30 found, 0 missing, 0 empty, 0 corrupted: 100% 30/30 [00:00<00:00, 198.69it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: data/val.cache\n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 5.95, Best Possible Recall (BPR) = 1.0000\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/50_img_AUG\n",
            "Starting training for 40 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      0/39      8.6G   0.07767   0.01812   0.01727    0.1131        36       640: 100% 7/7 [00:36<00:00,  5.19s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:05<00:00,  5.53s/it]\n",
            "                 all          30          52      0.0447      0.0385     0.00807     0.00156\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      1/39     10.1G   0.07684   0.01758   0.01656     0.111        42       640: 100% 7/7 [00:07<00:00,  1.07s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.14it/s]\n",
            "                 all          30          52       0.024      0.0556     0.00999     0.00192\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      2/39     10.1G   0.07293   0.01637   0.01394    0.1032        41       640: 100% 7/7 [00:06<00:00,  1.03it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.27it/s]\n",
            "                 all          30          52      0.0252      0.0698       0.013     0.00169\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      3/39     10.1G   0.07172   0.01563   0.01255    0.0999        35       640: 100% 7/7 [00:05<00:00,  1.26it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.16it/s]\n",
            "                 all          30          52      0.0456       0.111      0.0227     0.00287\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      4/39     10.1G   0.06812   0.01525   0.01201   0.09538        31       640: 100% 7/7 [00:05<00:00,  1.29it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.26it/s]\n",
            "                 all          30          52      0.0621      0.0926       0.028     0.00678\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      5/39     10.1G   0.06589   0.01548   0.01109   0.09246        47       640: 100% 7/7 [00:07<00:00,  1.08s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.09it/s]\n",
            "                 all          30          52      0.0603       0.111      0.0418     0.00773\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      6/39     10.1G    0.0627   0.01413   0.01092   0.08774        38       640: 100% 7/7 [00:05<00:00,  1.29it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.29it/s]\n",
            "                 all          30          52      0.0568       0.185      0.0449     0.00768\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      7/39     10.1G   0.06083   0.01399   0.01009   0.08492        26       640: 100% 7/7 [00:05<00:00,  1.26it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.37it/s]\n",
            "                 all          30          52      0.0807       0.185      0.0755      0.0139\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      8/39     10.1G   0.06062   0.01449  0.009211   0.08432        33       640: 100% 7/7 [00:06<00:00,  1.01it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.74it/s]\n",
            "                 all          30          52         0.1       0.125      0.0712      0.0158\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      9/39     10.1G   0.05617   0.01302  0.008146   0.07734        30       640: 100% 7/7 [00:05<00:00,  1.29it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.40it/s]\n",
            "                 all          30          52      0.0851       0.301       0.101      0.0279\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     10/39     10.1G    0.0545   0.01368  0.007317    0.0755        35       640: 100% 7/7 [00:06<00:00,  1.10it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.16it/s]\n",
            "                 all          30          52       0.228       0.321       0.166       0.058\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     11/39     10.1G   0.05231   0.01441  0.007116   0.07383        39       640: 100% 7/7 [00:07<00:00,  1.06s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.72it/s]\n",
            "                 all          30          52       0.317       0.493       0.297      0.0884\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     12/39     10.1G   0.05021   0.01299  0.006243   0.06944        30       640: 100% 7/7 [00:05<00:00,  1.20it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.56it/s]\n",
            "                 all          30          52       0.532       0.319       0.324       0.128\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     13/39     10.1G   0.05103   0.01369  0.005683   0.07041        34       640: 100% 7/7 [00:06<00:00,  1.11it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.29it/s]\n",
            "                 all          30          52       0.443       0.583       0.444       0.154\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     14/39     10.1G   0.04847   0.01283  0.005388   0.06669        23       640: 100% 7/7 [00:06<00:00,  1.04it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.67it/s]\n",
            "                 all          30          52       0.505       0.506       0.487       0.139\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     15/39     10.1G   0.04823   0.01349  0.004411   0.06612        43       640: 100% 7/7 [00:06<00:00,  1.16it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.68it/s]\n",
            "                 all          30          52        0.56       0.576       0.571        0.21\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     16/39     10.1G    0.0465   0.01173  0.004277   0.06251        27       640: 100% 7/7 [00:06<00:00,  1.06it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.48it/s]\n",
            "                 all          30          52       0.678       0.621       0.667       0.243\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     17/39     10.1G   0.04397   0.01127  0.003547   0.05879        27       640: 100% 7/7 [00:06<00:00,  1.03it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.63it/s]\n",
            "                 all          30          52       0.798       0.604       0.725       0.272\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     18/39     10.1G   0.04507    0.0112  0.003685   0.05995        31       640: 100% 7/7 [00:05<00:00,  1.25it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.59it/s]\n",
            "                 all          30          52       0.752       0.662       0.743       0.367\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     19/39     10.1G   0.04468    0.0108  0.003223   0.05871        33       640: 100% 7/7 [00:06<00:00,  1.13it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.53it/s]\n",
            "                 all          30          52         0.7       0.681       0.758       0.348\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     20/39     10.1G   0.04495   0.01037  0.003112   0.05844        31       640: 100% 7/7 [00:06<00:00,  1.14it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.35it/s]\n",
            "                 all          30          52       0.699       0.701        0.76       0.363\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     21/39     10.1G   0.04214    0.0109   0.00266    0.0557        40       640: 100% 7/7 [00:05<00:00,  1.23it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.56it/s]\n",
            "                 all          30          52       0.644       0.777       0.771       0.335\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     22/39     10.1G   0.04882   0.01022  0.002595   0.06163        37       640: 100% 7/7 [00:06<00:00,  1.08it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.42it/s]\n",
            "                 all          30          52       0.345       0.873       0.472        0.15\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     23/39     10.1G   0.05381  0.008951  0.002832   0.06559        34       640: 100% 7/7 [00:05<00:00,  1.19it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.53it/s]\n",
            "                 all          30          52       0.395       0.732       0.514       0.137\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     24/39     10.1G   0.05155   0.01045  0.002558   0.06456        39       640: 100% 7/7 [00:06<00:00,  1.10it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.12it/s]\n",
            "                 all          30          52       0.547        0.65       0.584       0.278\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     25/39     10.1G   0.04521   0.01075  0.002441    0.0584        29       640: 100% 7/7 [00:05<00:00,  1.28it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.50it/s]\n",
            "                 all          30          52       0.544       0.863       0.648       0.284\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     26/39     10.1G   0.04388   0.01013  0.002733   0.05674        36       640: 100% 7/7 [00:06<00:00,  1.10it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.60it/s]\n",
            "                 all          30          52       0.627       0.746       0.704       0.274\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     27/39     10.1G   0.04022   0.01162  0.002398   0.05424        39       640: 100% 7/7 [00:05<00:00,  1.28it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.53it/s]\n",
            "                 all          30          52       0.767       0.848       0.865       0.396\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     28/39     10.1G   0.03785   0.01034  0.002096   0.05029        34       640: 100% 7/7 [00:05<00:00,  1.21it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.39it/s]\n",
            "                 all          30          52       0.801       0.924         0.9        0.28\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     29/39     10.1G   0.03971   0.01036  0.002114   0.05218        28       640: 100% 7/7 [00:06<00:00,  1.16it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.89it/s]\n",
            "                 all          30          52        0.77       0.963       0.908        0.38\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     30/39     10.1G   0.04043  0.009181  0.002207   0.05182        30       640: 100% 7/7 [00:06<00:00,  1.13it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.62it/s]\n",
            "                 all          30          52       0.746       0.981       0.889       0.458\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     31/39     10.1G   0.03587   0.01039  0.001951   0.04821        34       640: 100% 7/7 [00:06<00:00,  1.06it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.48it/s]\n",
            "                 all          30          52       0.827       0.867       0.905       0.475\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     32/39     10.1G   0.03544  0.009943  0.001803   0.04718        26       640: 100% 7/7 [00:05<00:00,  1.24it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.38it/s]\n",
            "                 all          30          52       0.823       0.963       0.927       0.501\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     33/39     10.1G   0.03584    0.0102  0.001781   0.04783        38       640: 100% 7/7 [00:05<00:00,  1.29it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.32it/s]\n",
            "                 all          30          52       0.791       0.944       0.926       0.466\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     34/39     10.1G   0.03393  0.009695  0.001673   0.04529        31       640: 100% 7/7 [00:06<00:00,  1.09it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.08it/s]\n",
            "                 all          30          52       0.839       0.944       0.948       0.543\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     35/39     10.1G   0.03328  0.008937  0.001648   0.04387        32       640: 100% 7/7 [00:05<00:00,  1.29it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.58it/s]\n",
            "                 all          30          52       0.865       0.869       0.946       0.468\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     36/39     10.1G   0.03429  0.009461  0.001735   0.04549        35       640: 100% 7/7 [00:05<00:00,  1.18it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.46it/s]\n",
            "                 all          30          52        0.88       0.944       0.955       0.668\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     37/39     10.1G   0.03311    0.0096   0.00152   0.04423        41       640: 100% 7/7 [00:06<00:00,  1.10it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.62it/s]\n",
            "                 all          30          52       0.901       0.926       0.958       0.626\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     38/39     10.1G   0.03216  0.009903  0.001352   0.04341        34       640: 100% 7/7 [00:05<00:00,  1.26it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.63it/s]\n",
            "                 all          30          52       0.856       0.936       0.957        0.52\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     39/39     10.1G   0.03347  0.008892  0.001444    0.0438        42       640: 100% 7/7 [00:06<00:00,  1.17it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.40it/s]\n",
            "                 all          30          52       0.846       0.924       0.951       0.534\n",
            "                ball          30          25       0.807           1       0.967       0.548\n",
            "                hand          30          27       0.884       0.848       0.934       0.521\n",
            "40 epochs completed in 0.117 hours.\n",
            "\n",
            "Optimizer stripped from runs/train/50_img_AUG/weights/last.pt, 74.8MB\n",
            "Optimizer stripped from runs/train/50_img_AUG/weights/best.pt, 74.8MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training with 100 images"
      ],
      "metadata": {
        "id": "P3VHszC0iApH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training with normal dataset.\n",
        "\n",
        "This training trains with the pretrained model from the COCO dataset with the second dataset. After running it with 35 epochs, the best weights are under: best_100.pt\n",
        "\n",
        "Results:\n",
        "\n",
        "Results: \n",
        "*   Time: 10 minutes\n",
        "*   \n",
        "\n",
        "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.23it/s]\n",
        "                 all          30          52       0.861       0.889        0.93       0.528\n",
        "                ball          30          25       0.768           1       0.931       0.565\n",
        "                hand          30          27       0.955       0.777        0.93        0.49"
      ],
      "metadata": {
        "id": "fxPT6Hs-mNKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --workers 8 --device 0 --batch-size 15 --epochs 35 --img 640 640 --hyp data/50_images.yaml --name 100_img --weights 'yolov7_training.pt' --cfg cfg/training/yolov7.yaml"
      ],
      "metadata": {
        "id": "nLNsXSI0iEWX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3ef6a04-5024-4326-c9fa-5d19ba039118"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOR 🚀 2023-2-9 torch 1.13.1+cu116 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=15, bbox_interval=-1, bucket='', cache_images=False, cfg='cfg/training/yolov7.yaml', data='data/coco.yaml', device='0', entity=None, epochs=35, evolve=False, exist_ok=False, freeze=[0], global_rank=-1, hyp='data/50_images.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='100_img', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/100_img', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=15, upload_dataset=False, v5_metric=False, weights='yolov7_training.pt', workers=8, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "2023-03-07 10:48:22.473737: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-07 10:48:23.372209: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2023-03-07 10:48:23.372353: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2023-03-07 10:48:23.372375: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mtrain=data/50_images/train, val=data/50_images/val, nc=2, names=['ball', 'hand'], lr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, paste_in=0.0, loss_ota=1\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 12                -1  1         0  models.common.MP                        []                            \n",
            " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
            " 25                -1  1         0  models.common.MP                        []                            \n",
            " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 38                -1  1         0  models.common.MP                        []                            \n",
            " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
            " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
            " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 76                -1  1         0  models.common.MP                        []                            \n",
            " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
            " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 89                -1  1         0  models.common.MP                        []                            \n",
            " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
            " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
            " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
            "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
            "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
            "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
            "105   [102, 103, 104]  1     39550  models.yolo.IDetect                     [2, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 415 layers, 37201950 parameters, 37201950 gradients, 105.1 GFLOPS\n",
            "\n",
            "Transferred 555/566 items from yolov7_training.pt\n",
            "Scaled weight_decay = 0.00046875\n",
            "Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'data/train' images and labels... 99 found, 2 missing, 1 empty, 0 corrupted: 100% 101/101 [00:04<00:00, 23.00it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: data/train.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'data/val' images and labels... 30 found, 0 missing, 0 empty, 0 corrupted: 100% 30/30 [00:47<00:00,  1.60s/it]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: data/val.cache\n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 5.98, Best Possible Recall (BPR) = 1.0000\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/100_img\n",
            "Starting training for 35 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      0/34     9.47G   0.07847   0.01818    0.0181    0.1147        42       640: 100% 7/7 [00:44<00:00,  6.39s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:05<00:00,  5.51s/it]\n",
            "                 all          30          52      0.0584      0.0185     0.00863     0.00185\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      1/34       10G   0.07617    0.0178   0.01614    0.1101        45       640: 100% 7/7 [00:07<00:00,  1.13s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.23it/s]\n",
            "                 all          30          52      0.0237      0.0926      0.0135      0.0022\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      2/34       10G   0.07508   0.01636   0.01434    0.1058        47       640: 100% 7/7 [00:08<00:00,  1.28s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.32it/s]\n",
            "                 all          30          52      0.0217      0.0741      0.0117     0.00183\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      3/34       10G   0.07494   0.01534   0.01306    0.1033        29       640: 100% 7/7 [00:05<00:00,  1.18it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.89it/s]\n",
            "                 all          30          52      0.0502      0.0926      0.0255     0.00366\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      4/34       10G   0.07015   0.01546   0.01162   0.09724        47       640: 100% 7/7 [00:06<00:00,  1.04it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.30it/s]\n",
            "                 all          30          52      0.0526      0.0741      0.0251     0.00463\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      5/34       10G   0.06769   0.01518   0.01129   0.09415        37       640: 100% 7/7 [00:06<00:00,  1.05it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.11it/s]\n",
            "                 all          30          52       0.164       0.037      0.0331     0.00766\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      6/34       10G   0.06472   0.01443   0.01046    0.0896        43       640: 100% 7/7 [00:05<00:00,  1.21it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.51it/s]\n",
            "                 all          30          52       0.159        0.15       0.105      0.0186\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      7/34       10G   0.06136   0.01357   0.00917    0.0841        34       640: 100% 7/7 [00:06<00:00,  1.06it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.86it/s]\n",
            "                 all          30          52       0.141       0.167       0.112      0.0251\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      8/34       10G   0.05931   0.01428  0.008436   0.08203        46       640: 100% 7/7 [00:06<00:00,  1.03it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.11it/s]\n",
            "                 all          30          52       0.311       0.168       0.148       0.032\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      9/34       10G   0.05489   0.01314  0.007786   0.07581        32       640: 100% 7/7 [00:05<00:00,  1.23it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.40it/s]\n",
            "                 all          30          52       0.406       0.264       0.222      0.0502\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     10/34       10G   0.05213   0.01403  0.007017   0.07318        47       640: 100% 7/7 [00:06<00:00,  1.07it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.20it/s]\n",
            "                 all          30          52        0.32       0.311         0.3      0.0843\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     11/34       10G   0.05116   0.01355  0.005882    0.0706        34       640: 100% 7/7 [00:06<00:00,  1.01it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.19it/s]\n",
            "                 all          30          52       0.422       0.445       0.403       0.117\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     12/34       10G   0.05064   0.01244  0.005263   0.06835        35       640: 100% 7/7 [00:05<00:00,  1.22it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.81it/s]\n",
            "                 all          30          52       0.373       0.735       0.457       0.125\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     13/34       10G   0.04974   0.01343  0.005243   0.06842        40       640: 100% 7/7 [00:06<00:00,  1.10it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.12it/s]\n",
            "                 all          30          52       0.612       0.591       0.577       0.197\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     14/34       10G   0.04869   0.01169  0.004577   0.06496        25       640: 100% 7/7 [00:07<00:00,  1.03s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.64it/s]\n",
            "                 all          30          52       0.747       0.736       0.717       0.228\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     15/34       10G   0.04819   0.01254  0.004428   0.06515        29       640: 100% 7/7 [00:05<00:00,  1.17it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.17it/s]\n",
            "                 all          30          52       0.718       0.793       0.785       0.308\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     16/34       10G   0.04711   0.01153  0.004118   0.06275        43       640: 100% 7/7 [00:06<00:00,  1.10it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.03it/s]\n",
            "                 all          30          52       0.709        0.81       0.828       0.347\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     17/34       10G   0.04889   0.01018   0.00588   0.06494        22       640: 100% 7/7 [00:07<00:00,  1.00s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.76it/s]\n",
            "                 all          30          52       0.702       0.861       0.839       0.378\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     18/34       10G   0.04528   0.01175  0.003884   0.06092        37       640: 100% 7/7 [00:05<00:00,  1.20it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.43it/s]\n",
            "                 all          30          52       0.655       0.833       0.827       0.395\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     19/34       10G   0.04446   0.01115  0.003174   0.05879        45       640: 100% 7/7 [00:06<00:00,  1.16it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.60it/s]\n",
            "                 all          30          52       0.686       0.792       0.803       0.347\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     20/34       10G   0.04191   0.01055  0.003057   0.05552        35       640: 100% 7/7 [00:06<00:00,  1.07it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.72it/s]\n",
            "                 all          30          52       0.775       0.827       0.876       0.421\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     21/34       10G   0.04087   0.01041  0.002653   0.05394        31       640: 100% 7/7 [00:05<00:00,  1.22it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.59it/s]\n",
            "                 all          30          52       0.818       0.861       0.893       0.407\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     22/34       10G   0.04723   0.01009  0.002775   0.06009        26       640: 100% 7/7 [00:06<00:00,  1.01it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.40it/s]\n",
            "                 all          30          52       0.671       0.881       0.769       0.323\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     23/34       10G   0.04654   0.01011  0.002693   0.05934        30       640: 100% 7/7 [00:05<00:00,  1.25it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.25it/s]\n",
            "                 all          30          52       0.669       0.846       0.803       0.311\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     24/34       10G   0.04442   0.01083  0.002914   0.05816        34       640: 100% 7/7 [00:06<00:00,  1.06it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.55it/s]\n",
            "                 all          30          52       0.769        0.83       0.843       0.369\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     25/34       10G   0.04417  0.009546   0.00278    0.0565        34       640: 100% 7/7 [00:05<00:00,  1.21it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.66it/s]\n",
            "                 all          30          52       0.717       0.869       0.843         0.4\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     26/34       10G   0.04101   0.01036  0.002647   0.05401        37       640: 100% 7/7 [00:05<00:00,  1.24it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.53it/s]\n",
            "                 all          30          52       0.692       0.866       0.711       0.254\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     27/34       10G   0.04149   0.01096  0.002468   0.05492        38       640: 100% 7/7 [00:06<00:00,  1.09it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.14it/s]\n",
            "                 all          30          52       0.815       0.924       0.891       0.437\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     28/34       10G   0.03723   0.01039  0.002415   0.05003        40       640: 100% 7/7 [00:06<00:00,  1.16it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.41it/s]\n",
            "                 all          30          52       0.849       0.793       0.892       0.394\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     29/34       10G   0.03889    0.0104  0.002489   0.05178        34       640: 100% 7/7 [00:07<00:00,  1.02s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.08it/s]\n",
            "                 all          30          52        0.79        0.87       0.896       0.547\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     30/34       10G   0.03752   0.01025  0.002113   0.04989        40       640: 100% 7/7 [00:05<00:00,  1.21it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.56it/s]\n",
            "                 all          30          52       0.804       0.907        0.92       0.518\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     31/34       10G   0.03615   0.01003  0.002419   0.04861        31       640: 100% 7/7 [00:05<00:00,  1.23it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.33it/s]\n",
            "                 all          30          52       0.854       0.907        0.93       0.565\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     32/34       10G   0.03637  0.009863  0.002203   0.04843        38       640: 100% 7/7 [00:06<00:00,  1.04it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.54it/s]\n",
            "                 all          30          52       0.786       0.926       0.923        0.49\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     33/34       10G   0.03526  0.009867  0.002297   0.04742        37       640: 100% 7/7 [00:06<00:00,  1.08it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.24it/s]\n",
            "                 all          30          52       0.786       0.887       0.921       0.406\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     34/34       10G    0.0349  0.009826  0.002135   0.04686        39       640: 100% 7/7 [00:05<00:00,  1.18it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.23it/s]\n",
            "                 all          30          52       0.861       0.889        0.93       0.528\n",
            "                ball          30          25       0.768           1       0.931       0.565\n",
            "                hand          30          27       0.955       0.777        0.93        0.49\n",
            "35 epochs completed in 0.108 hours.\n",
            "\n",
            "Optimizer stripped from runs/train/100_img/weights/last.pt, 74.8MB\n",
            "Optimizer stripped from runs/train/100_img/weights/best.pt, 74.8MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training with augmented dataset\n",
        "\n",
        "This training trains with the augmented dataset from the COCO dataset with the second dataset. After running it with 35 epochs, the best weights are under: best_100AUG.pt\n",
        "\n",
        "Results:\n",
        "\n",
        "Results: \n",
        "*   Time: 10 minutes\n",
        "*   \n",
        "\n",
        "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.16it/s]\n",
        "                 all          30          52       0.912        0.98       0.988       0.755\n",
        "                ball          30          25       0.862           1       0.994       0.755\n",
        "                hand          30          27       0.963       0.959       0.983       0.756"
      ],
      "metadata": {
        "id": "zbUDjVABmTX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --workers 8 --device 0 --batch-size 15 --epochs 35 --img 640 640 --hyp data/50_images.yaml --name 100_img_AUG --weights 'yolov7_training.pt' --cfg cfg/training/yolov7.yaml"
      ],
      "metadata": {
        "id": "ydU5QheQmYTk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94f60a2a-a9ad-401c-bf0c-8f933db9c26a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOR 🚀 2023-2-9 torch 1.13.1+cu116 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=15, bbox_interval=-1, bucket='', cache_images=False, cfg='cfg/training/yolov7.yaml', data='data/coco.yaml', device='0', entity=None, epochs=35, evolve=False, exist_ok=False, freeze=[0], global_rank=-1, hyp='data/50_images.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='100_img_AUG', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/100_img_AUG2', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=15, upload_dataset=False, v5_metric=False, weights='yolov7_training.pt', workers=8, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "2023-03-07 11:03:02.426841: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-07 11:03:03.331703: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2023-03-07 11:03:03.331844: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2023-03-07 11:03:03.331866: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mtrain=data/50_images/train, val=data/50_images/val, nc=2, names=['ball', 'hand'], lr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, paste_in=0.0, loss_ota=1\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 12                -1  1         0  models.common.MP                        []                            \n",
            " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
            " 25                -1  1         0  models.common.MP                        []                            \n",
            " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 38                -1  1         0  models.common.MP                        []                            \n",
            " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
            " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
            " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 76                -1  1         0  models.common.MP                        []                            \n",
            " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
            " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 89                -1  1         0  models.common.MP                        []                            \n",
            " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
            " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
            " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
            "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
            "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
            "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
            "105   [102, 103, 104]  1     39550  models.yolo.IDetect                     [2, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 415 layers, 37201950 parameters, 37201950 gradients, 105.1 GFLOPS\n",
            "\n",
            "Transferred 555/566 items from yolov7_training.pt\n",
            "Scaled weight_decay = 0.00046875\n",
            "Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'data/train' images and labels... 198 found, 2 missing, 2 empty, 0 corrupted: 100% 200/200 [00:05<00:00, 38.09it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: data/train.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'data/val.cache' images and labels... 30 found, 0 missing, 0 empty, 0 corrupted: 100% 30/30 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 6.00, Best Possible Recall (BPR) = 1.0000\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/100_img_AUG2\n",
            "Starting training for 35 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      0/34     9.45G    0.0782   0.01804   0.01698    0.1132        23       640: 100% 14/14 [00:39<00:00,  2.83s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:05<00:00,  5.58s/it]\n",
            "                 all          30          52      0.0209      0.0741      0.0107     0.00237\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      1/34     9.92G   0.07137     0.016   0.01416    0.1015         9       640: 100% 14/14 [00:14<00:00,  1.07s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.68it/s]\n",
            "                 all          30          52      0.0404       0.131      0.0235     0.00392\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      2/34     9.92G   0.06987   0.01498   0.01154   0.09638        16       640: 100% 14/14 [00:13<00:00,  1.07it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.94it/s]\n",
            "                 all          30          52      0.0683      0.0756      0.0461     0.00589\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      3/34     9.92G   0.06485   0.01412   0.01045   0.08942        16       640: 100% 14/14 [00:12<00:00,  1.11it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.64it/s]\n",
            "                 all          30          52       0.109       0.153      0.0748      0.0169\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      4/34     9.92G   0.05758   0.01369  0.008259   0.07953         7       640: 100% 14/14 [00:12<00:00,  1.09it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.88it/s]\n",
            "                 all          30          52       0.159       0.278       0.128      0.0269\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      5/34     9.92G    0.0544   0.01389  0.006974   0.07526        10       640: 100% 14/14 [00:12<00:00,  1.16it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.99it/s]\n",
            "                 all          30          52        0.43       0.367        0.33       0.102\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      6/34     9.92G   0.05058   0.01294  0.005446   0.06896        15       640: 100% 14/14 [00:11<00:00,  1.18it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.18it/s]\n",
            "                 all          30          52       0.422       0.496       0.437       0.128\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      7/34     9.92G   0.05108   0.01211  0.004755   0.06794        18       640: 100% 14/14 [00:12<00:00,  1.13it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.26it/s]\n",
            "                 all          30          52       0.339       0.646       0.394       0.121\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      8/34     9.92G    0.0493   0.01115  0.003666   0.06412        15       640: 100% 14/14 [00:12<00:00,  1.15it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.54it/s]\n",
            "                 all          30          52       0.607       0.607       0.598       0.189\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      9/34     9.92G   0.04833   0.01044   0.00346   0.06223        26       640: 100% 14/14 [00:12<00:00,  1.12it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.97it/s]\n",
            "                 all          30          52       0.387       0.718       0.488       0.176\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     10/34     9.92G   0.04525   0.01016  0.002554   0.05796        16       640: 100% 14/14 [00:13<00:00,  1.01it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.06it/s]\n",
            "                 all          30          52       0.677       0.846       0.818       0.449\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     11/34     9.92G   0.05432  0.009418   0.00281   0.06654        18       640: 100% 14/14 [00:12<00:00,  1.13it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.05it/s]\n",
            "                 all          30          52       0.687       0.772       0.754       0.247\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     12/34     9.92G   0.05078  0.009471  0.002677   0.06292        15       640: 100% 14/14 [00:12<00:00,  1.14it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.05it/s]\n",
            "                 all          30          52       0.745       0.828       0.816       0.299\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     13/34     9.92G   0.04714   0.01009  0.002896   0.06012        19       640: 100% 14/14 [00:12<00:00,  1.09it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.75it/s]\n",
            "                 all          30          52        0.58       0.856       0.613       0.207\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     14/34     9.92G   0.04567  0.009595  0.002907   0.05817        15       640: 100% 14/14 [00:12<00:00,  1.09it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.78it/s]\n",
            "                 all          30          52       0.768       0.898       0.866       0.391\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     15/34     9.92G   0.04362  0.009298  0.002458   0.05538        20       640: 100% 14/14 [00:13<00:00,  1.06it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.35it/s]\n",
            "                 all          30          52        0.77       0.904        0.87       0.307\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     16/34     9.92G   0.04214  0.008964  0.002607   0.05372        12       640: 100% 14/14 [00:12<00:00,  1.09it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.06it/s]\n",
            "                 all          30          52       0.856       0.924       0.924       0.493\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     17/34     9.92G   0.04099  0.009313  0.002265   0.05257        25       640: 100% 14/14 [00:13<00:00,  1.07it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.81it/s]\n",
            "                 all          30          52       0.869       0.963       0.964       0.531\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     18/34     9.92G   0.03981  0.009052  0.002265   0.05113        20       640: 100% 14/14 [00:12<00:00,  1.12it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.77it/s]\n",
            "                 all          30          52       0.765       0.846       0.825       0.487\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     19/34     9.92G   0.03889  0.008809  0.002135   0.04984        18       640: 100% 14/14 [00:12<00:00,  1.10it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.03it/s]\n",
            "                 all          30          52       0.883       0.942       0.938       0.468\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     20/34     9.92G   0.03838  0.008677  0.002098   0.04915        24       640: 100% 14/14 [00:12<00:00,  1.12it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.96it/s]\n",
            "                 all          30          52       0.864       0.867       0.896       0.459\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     21/34     9.92G   0.03595  0.008299  0.001943   0.04619        19       640: 100% 14/14 [00:13<00:00,  1.06it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.14it/s]\n",
            "                 all          30          52       0.903       0.963       0.973       0.533\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     22/34     9.92G    0.0337  0.008092  0.001937   0.04372        12       640: 100% 14/14 [00:12<00:00,  1.14it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.02it/s]\n",
            "                 all          30          52        0.89       0.981       0.974       0.463\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     23/34     9.92G   0.03306   0.00777  0.001816   0.04265        12       640: 100% 14/14 [00:12<00:00,  1.14it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.20it/s]\n",
            "                 all          30          52       0.959       0.929       0.979       0.576\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     24/34     9.92G   0.03019  0.007678   0.00165   0.03952        16       640: 100% 14/14 [00:12<00:00,  1.15it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.11it/s]\n",
            "                 all          30          52       0.912       0.959       0.974       0.655\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     25/34     9.92G   0.03079  0.007711   0.00161   0.04011        15       640: 100% 14/14 [00:12<00:00,  1.15it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.92it/s]\n",
            "                 all          30          52        0.88       0.963       0.968       0.668\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     26/34     9.92G   0.03022  0.007324  0.001559    0.0391         9       640: 100% 14/14 [00:12<00:00,  1.14it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.36it/s]\n",
            "                 all          30          52       0.835       0.871       0.961       0.619\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     27/34     9.92G   0.02859  0.007364   0.00148   0.03743        23       640: 100% 14/14 [00:12<00:00,  1.15it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.15it/s]\n",
            "                 all          30          52       0.912       0.963       0.977       0.755\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     28/34     9.92G   0.02748  0.007322  0.001386   0.03619        18       640: 100% 14/14 [00:12<00:00,  1.11it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.84it/s]\n",
            "                 all          30          52       0.914       0.963       0.977        0.68\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     29/34     9.92G   0.02657  0.007269  0.001349   0.03519        22       640: 100% 14/14 [00:13<00:00,  1.07it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.01it/s]\n",
            "                 all          30          52       0.913       0.981       0.979       0.693\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     30/34     9.92G   0.02648  0.006757  0.001248   0.03448        10       640: 100% 14/14 [00:12<00:00,  1.13it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.07it/s]\n",
            "                 all          30          52       0.898       0.976       0.978       0.686\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     31/34     9.92G   0.02487   0.00646  0.001141   0.03247        13       640: 100% 14/14 [00:11<00:00,  1.17it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.59it/s]\n",
            "                 all          30          52       0.917       0.963       0.982        0.67\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     32/34     9.92G   0.02383  0.006723   0.00113   0.03168        24       640: 100% 14/14 [00:12<00:00,  1.14it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.03it/s]\n",
            "                 all          30          52       0.917       0.963       0.987       0.719\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     33/34     9.92G   0.02721  0.006735 0.0009703   0.03491        12       640: 100% 14/14 [00:12<00:00,  1.12it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.16it/s]\n",
            "                 all          30          52       0.916       0.963       0.988       0.594\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     34/34     9.92G   0.02747  0.006842  0.001178   0.03549        20       640: 100% 14/14 [00:12<00:00,  1.13it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.16it/s]\n",
            "                 all          30          52       0.912        0.98       0.988       0.755\n",
            "                ball          30          25       0.862           1       0.994       0.755\n",
            "                hand          30          27       0.963       0.959       0.983       0.756\n",
            "35 epochs completed in 0.164 hours.\n",
            "\n",
            "Optimizer stripped from runs/train/100_img_AUG2/weights/last.pt, 74.8MB\n",
            "Optimizer stripped from runs/train/100_img_AUG2/weights/best.pt, 74.8MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training with 240 images"
      ],
      "metadata": {
        "id": "z983kByIiIJf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training with normal dataset.\n",
        "\n",
        "This training trains with the normal dataset from the COCO dataset with the third dataset. After running it with 35 epochs, the best weights are under: best_240.pt\n",
        "\n",
        "\n",
        "Results: \n",
        "*   Time: 15 minutes\n",
        "*   \n",
        "\n",
        "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.03it/s]\n",
        "                 all          30          52       0.909       0.963       0.986       0.755\n",
        "                ball          30          25       0.856           1       0.991       0.747\n",
        "                hand          30          27       0.961       0.926        0.98       0.762"
      ],
      "metadata": {
        "id": "DHgF8Lc2mdcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --workers 8 --device 0 --batch-size 15 --epochs 35 --img 640 640 --hyp data/50_images.yaml --name 250_img --weights 'yolov7_training.pt' --cfg cfg/training/yolov7.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZSfZlxViKdT",
        "outputId": "72781a83-25fc-4983-cde7-afb460f81a8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOR 🚀 2023-2-9 torch 1.13.1+cu116 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=15, bbox_interval=-1, bucket='', cache_images=False, cfg='cfg/training/yolov7.yaml', data='data/coco.yaml', device='0', entity=None, epochs=35, evolve=False, exist_ok=False, freeze=[0], global_rank=-1, hyp='data/50_images.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='250_img', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/250_img', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=15, upload_dataset=False, v5_metric=False, weights='yolov7_training.pt', workers=8, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "2023-03-01 23:59:12.477472: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-01 23:59:14.932230: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2023-03-01 23:59:14.934789: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2023-03-01 23:59:14.934825: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mtrain=data/50_images/train, val=data/50_images/val, nc=2, names=['ball', 'hand'], lr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, paste_in=0.0, loss_ota=1\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 12                -1  1         0  models.common.MP                        []                            \n",
            " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
            " 25                -1  1         0  models.common.MP                        []                            \n",
            " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 38                -1  1         0  models.common.MP                        []                            \n",
            " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
            " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
            " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 76                -1  1         0  models.common.MP                        []                            \n",
            " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
            " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 89                -1  1         0  models.common.MP                        []                            \n",
            " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
            " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
            " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
            "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
            "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
            "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
            "105   [102, 103, 104]  1     39550  models.yolo.IDetect                     [2, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 415 layers, 37201950 parameters, 37201950 gradients, 105.1 GFLOPS\n",
            "\n",
            "Transferred 555/566 items from yolov7_training.pt\n",
            "Scaled weight_decay = 0.00046875\n",
            "Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'data/train' images and labels... 235 found, 8 missing, 5 empty, 0 corrupted: 100% 243/243 [00:04<00:00, 58.94it/s] \n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: data/train.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'data/val' images and labels... 30 found, 0 missing, 0 empty, 0 corrupted: 100% 30/30 [00:00<00:00, 170.28it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: data/val.cache\n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 5.87, Best Possible Recall (BPR) = 1.0000\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/250_img\n",
            "Starting training for 35 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      0/34     7.25G   0.07684    0.0174   0.01635    0.1106         8       640: 100% 17/17 [00:40<00:00,  2.41s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:05<00:00,  5.50s/it]\n",
            "                 all          30          52      0.0266       0.111       0.016     0.00409\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      1/34     10.1G   0.07117   0.01539   0.01271   0.09926         6       640: 100% 17/17 [00:18<00:00,  1.06s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.91it/s]\n",
            "                 all          30          52      0.0437       0.131      0.0271     0.00644\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      2/34     10.1G   0.06466   0.01476   0.01043   0.08985         9       640: 100% 17/17 [00:15<00:00,  1.06it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.42it/s]\n",
            "                 all          30          52       0.129      0.0926      0.0673       0.013\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      3/34     10.1G   0.05832   0.01411  0.008488   0.08091         9       640: 100% 17/17 [00:16<00:00,  1.06it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.22it/s]\n",
            "                 all          30          52       0.162       0.261       0.109      0.0239\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      4/34     10.1G   0.05414   0.01415  0.006338   0.07462        15       640: 100% 17/17 [00:16<00:00,  1.05it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.08it/s]\n",
            "                 all          30          52       0.319        0.59       0.328       0.106\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      5/34     10.1G   0.04895   0.01301  0.004792   0.06676         4       640: 100% 17/17 [00:16<00:00,  1.03it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.22it/s]\n",
            "                 all          30          52       0.421       0.522       0.508       0.175\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      6/34     10.1G   0.05027   0.01122  0.003658   0.06515         8       640: 100% 17/17 [00:16<00:00,  1.02it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.81it/s]\n",
            "                 all          30          52       0.587       0.715       0.626       0.237\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      7/34     10.1G   0.04723   0.01038  0.003201   0.06082         6       640: 100% 17/17 [00:16<00:00,  1.06it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.00it/s]\n",
            "                 all          30          52       0.542       0.786       0.649       0.245\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      8/34     10.1G   0.04509   0.01007  0.002653   0.05781         8       640: 100% 17/17 [00:15<00:00,  1.10it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.09it/s]\n",
            "                 all          30          52       0.677       0.767       0.807       0.279\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      9/34     10.1G   0.05192  0.009258  0.002784   0.06396        10       640: 100% 17/17 [00:15<00:00,  1.09it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.02it/s]\n",
            "                 all          30          52       0.442       0.425       0.523       0.201\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     10/34     10.1G   0.04935  0.009693  0.003983   0.06303         6       640: 100% 17/17 [00:15<00:00,  1.10it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.08it/s]\n",
            "                 all          30          52       0.559       0.901       0.761       0.215\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     11/34     10.1G   0.04422   0.01041   0.00321   0.05784         6       640: 100% 17/17 [00:15<00:00,  1.11it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.24it/s]\n",
            "                 all          30          52       0.769        0.79       0.849       0.392\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     12/34     10.1G   0.04607   0.01004  0.002678   0.05879        15       640: 100% 17/17 [00:18<00:00,  1.07s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.63it/s]\n",
            "                 all          30          52       0.654       0.859       0.798       0.386\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     13/34     10.1G   0.04205  0.009928  0.002821    0.0548        13       640: 100% 17/17 [00:15<00:00,  1.13it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.13it/s]\n",
            "                 all          30          52       0.687       0.864        0.85       0.333\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     14/34     10.1G   0.04327  0.008536  0.002829   0.05463         6       640: 100% 17/17 [00:15<00:00,  1.12it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.29it/s]\n",
            "                 all          30          52       0.802       0.933       0.916       0.578\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     15/34     10.1G   0.04134  0.008588  0.002292   0.05222         6       640: 100% 17/17 [00:15<00:00,  1.08it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.09it/s]\n",
            "                 all          30          52       0.808       0.943       0.923       0.423\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     16/34     10.1G   0.03813  0.008775  0.002243   0.04915        13       640: 100% 17/17 [00:15<00:00,  1.13it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.25it/s]\n",
            "                 all          30          52       0.845       0.944       0.956       0.545\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     17/34     10.1G   0.03614  0.008435  0.002004   0.04657        12       640: 100% 17/17 [00:15<00:00,  1.13it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.34it/s]\n",
            "                 all          30          52       0.854       0.944       0.943       0.646\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     18/34     10.1G   0.03611  0.008076  0.001902   0.04609        12       640: 100% 17/17 [00:15<00:00,  1.09it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.23it/s]\n",
            "                 all          30          52       0.914       0.963       0.968       0.671\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     19/34     10.1G   0.03417  0.007144  0.001675   0.04299         9       640: 100% 17/17 [00:15<00:00,  1.07it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.90it/s]\n",
            "                 all          30          52       0.918       0.981       0.979       0.596\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     20/34     10.1G   0.03347  0.007105  0.001658   0.04223        10       640: 100% 17/17 [00:15<00:00,  1.11it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.28it/s]\n",
            "                 all          30          52        0.96       0.925       0.974       0.663\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     21/34     10.1G   0.03255  0.007126  0.001675   0.04135        13       640: 100% 17/17 [00:15<00:00,  1.12it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.10it/s]\n",
            "                 all          30          52       0.901       0.963       0.972       0.612\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     22/34     10.1G   0.03045  0.007138  0.001545   0.03914         8       640: 100% 17/17 [00:14<00:00,  1.14it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.42it/s]\n",
            "                 all          30          52        0.92       0.963       0.975       0.701\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     23/34     10.1G   0.03032  0.006647  0.001386   0.03835        10       640: 100% 17/17 [00:16<00:00,  1.05it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.29it/s]\n",
            "                 all          30          52       0.827       0.811        0.88       0.464\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     24/34     10.1G   0.02847  0.006619  0.001333   0.03642         7       640: 100% 17/17 [00:15<00:00,  1.11it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.12it/s]\n",
            "                 all          30          52       0.916       0.963       0.982       0.711\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     25/34     10.1G   0.02759   0.00664  0.001256   0.03549        10       640: 100% 17/17 [00:16<00:00,  1.01it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.55it/s]\n",
            "                 all          30          52       0.895       0.981       0.981       0.619\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     26/34     10.1G   0.02751  0.007017  0.001269   0.03579        16       640: 100% 17/17 [00:15<00:00,  1.10it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.23it/s]\n",
            "                 all          30          52       0.884       0.981       0.981       0.689\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     27/34     10.1G   0.03597  0.006481   0.00141   0.04386        10       640: 100% 17/17 [00:14<00:00,  1.15it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.96it/s]\n",
            "                 all          30          52       0.925       0.949       0.978       0.691\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     28/34     10.1G   0.02586  0.006546  0.001514   0.03392         8       640: 100% 17/17 [00:14<00:00,  1.14it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.23it/s]\n",
            "                 all          30          52       0.926       0.936       0.982       0.735\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     29/34     10.1G    0.0267  0.006682  0.001388   0.03477        11       640: 100% 17/17 [00:15<00:00,  1.09it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.34it/s]\n",
            "                 all          30          52        0.92       0.944       0.983       0.646\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     30/34     10.1G   0.02522  0.006505  0.001181    0.0329         9       640: 100% 17/17 [00:14<00:00,  1.13it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.20it/s]\n",
            "                 all          30          52       0.875       0.981       0.985       0.728\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     31/34     10.1G   0.02531  0.006454  0.001054   0.03282        16       640: 100% 17/17 [00:15<00:00,  1.09it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.52it/s]\n",
            "                 all          30          52       0.908       0.981       0.986       0.745\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     32/34     10.1G   0.02416  0.006157  0.001048   0.03137         6       640: 100% 17/17 [00:16<00:00,  1.05it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.19it/s]\n",
            "                 all          30          52       0.891       0.981       0.982       0.747\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     33/34     10.1G     0.023  0.006116  0.001022   0.03013         7       640: 100% 17/17 [00:15<00:00,  1.06it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.96it/s]\n",
            "                 all          30          52       0.883       0.981       0.985       0.737\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     34/34     10.1G    0.0239  0.005893 0.0009818   0.03077         7       640: 100% 17/17 [00:16<00:00,  1.05it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.03it/s]\n",
            "                 all          30          52       0.909       0.963       0.986       0.755\n",
            "                ball          30          25       0.856           1       0.991       0.747\n",
            "                hand          30          27       0.961       0.926        0.98       0.762\n",
            "35 epochs completed in 0.195 hours.\n",
            "\n",
            "Optimizer stripped from runs/train/250_img/weights/last.pt, 74.8MB\n",
            "Optimizer stripped from runs/train/250_img/weights/best.pt, 74.8MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training with augmented dataset.\n",
        "\n",
        "This training trains with the augmented dataset from the COCO dataset with the third dataset. After running it with 35 epochs, the best weights are under: best_240AUG.pt\n",
        "\n",
        "\n",
        "Results: \n",
        "*   Time: 20 minutes\n",
        "*   \n",
        "\n",
        "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.91it/s]\n",
        "                 all          30          52       0.944           1       0.992       0.792\n",
        "                ball          30          25       0.888           1       0.988       0.762\n",
        "                hand          30          27           1           1       0.996       0.823"
      ],
      "metadata": {
        "id": "AxN38JzrmjbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --workers 8 --device 0 --batch-size 15 --epochs 35 --img 640 640 --hyp data/50_images.yaml --name 250_img_AUG --weights 'yolov7_training.pt' --cfg cfg/training/yolov7.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwB0T2RQmpNK",
        "outputId": "04f69ea7-d3ff-4499-9a71-04dfbcabeb53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOR 🚀 2023-2-9 torch 1.13.1+cu116 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=15, bbox_interval=-1, bucket='', cache_images=False, cfg='cfg/training/yolov7.yaml', data='data/coco.yaml', device='0', entity=None, epochs=35, evolve=False, exist_ok=False, freeze=[0], global_rank=-1, hyp='data/50_images.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='250_img_AUG', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/250_img_AUG2', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=15, upload_dataset=False, v5_metric=False, weights='yolov7_training.pt', workers=8, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "2023-03-02 00:29:11.138169: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-02 00:29:12.120196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2023-03-02 00:29:12.120343: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2023-03-02 00:29:12.120365: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mtrain=data/50_images/train, val=data/50_images/val, nc=2, names=['ball', 'hand'], lr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, paste_in=0.0, loss_ota=1\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 12                -1  1         0  models.common.MP                        []                            \n",
            " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
            " 25                -1  1         0  models.common.MP                        []                            \n",
            " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 38                -1  1         0  models.common.MP                        []                            \n",
            " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
            " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
            " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 76                -1  1         0  models.common.MP                        []                            \n",
            " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
            " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 89                -1  1         0  models.common.MP                        []                            \n",
            " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
            " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
            " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
            "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
            "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
            "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
            "105   [102, 103, 104]  1     39550  models.yolo.IDetect                     [2, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 415 layers, 37201950 parameters, 37201950 gradients, 105.1 GFLOPS\n",
            "\n",
            "Transferred 555/566 items from yolov7_training.pt\n",
            "Scaled weight_decay = 0.00046875\n",
            "Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'data/train' images and labels... 470 found, 8 missing, 10 empty, 0 corrupted: 100% 478/478 [00:02<00:00, 230.51it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: data/train.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'data/val' images and labels... 30 found, 0 missing, 0 empty, 0 corrupted: 100% 30/30 [00:00<00:00, 185.17it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: data/val.cache\n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 5.90, Best Possible Recall (BPR) = 1.0000\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/250_img_AUG2\n",
            "Starting training for 35 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      0/34     8.63G    0.0752   0.01663   0.01483    0.1067        47       640: 100% 32/32 [01:01<00:00,  1.94s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:05<00:00,  5.58s/it]\n",
            "                 all          30          52      0.0525      0.0741      0.0323     0.00472\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      1/34     10.1G   0.06337   0.01464   0.01029    0.0883        50       640: 100% 32/32 [00:32<00:00,  1.03s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.48it/s]\n",
            "                 all          30          52       0.172       0.204       0.181      0.0574\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      2/34     10.1G   0.05341   0.01357  0.006415    0.0734        45       640: 100% 32/32 [00:30<00:00,  1.05it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.39it/s]\n",
            "                 all          30          52       0.531       0.696       0.629       0.242\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      3/34     10.1G   0.04851   0.01152  0.003856   0.06389        66       640: 100% 32/32 [00:30<00:00,  1.04it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.69it/s]\n",
            "                 all          30          52       0.717       0.756       0.787       0.291\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      4/34     10.1G   0.04743   0.01018  0.002687   0.06029        51       640: 100% 32/32 [00:30<00:00,  1.05it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.75it/s]\n",
            "                 all          30          52       0.403       0.585       0.435       0.132\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      5/34     10.1G   0.05078   0.01037  0.003675   0.06483        41       640: 100% 32/32 [00:29<00:00,  1.08it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.81it/s]\n",
            "                 all          30          52        0.67       0.769       0.747       0.375\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      6/34     10.1G   0.04856   0.01008  0.003665   0.06231        58       640: 100% 32/32 [00:29<00:00,  1.09it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.78it/s]\n",
            "                 all          30          52       0.597        0.88       0.865       0.418\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      7/34     10.1G   0.04269  0.009744  0.002837   0.05527        66       640: 100% 32/32 [00:29<00:00,  1.07it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.60it/s]\n",
            "                 all          30          52       0.814       0.922       0.926       0.512\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      8/34     10.1G   0.04033  0.008968  0.002622   0.05192        40       640: 100% 32/32 [00:29<00:00,  1.09it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.35it/s]\n",
            "                 all          30          52       0.871       0.941       0.964       0.504\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      9/34     10.1G   0.03768  0.008126  0.002502   0.04831        39       640: 100% 32/32 [00:29<00:00,  1.09it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.64it/s]\n",
            "                 all          30          52       0.971       0.944       0.974       0.659\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     10/34     10.1G   0.03633  0.007271  0.002194    0.0458        32       640: 100% 32/32 [00:30<00:00,  1.06it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.66it/s]\n",
            "                 all          30          52       0.981       0.944       0.982       0.503\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     11/34     10.1G   0.03569   0.00726  0.001689   0.04464        44       640: 100% 32/32 [00:28<00:00,  1.11it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.69it/s]\n",
            "                 all          30          52       0.841       0.863       0.912       0.517\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     12/34     10.1G   0.03265  0.006584   0.00178   0.04102        50       640: 100% 32/32 [00:28<00:00,  1.11it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.87it/s]\n",
            "                 all          30          52       0.942       0.963       0.974       0.626\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     13/34     10.1G   0.03064  0.006572  0.001492    0.0387        52       640: 100% 32/32 [00:29<00:00,  1.09it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.78it/s]\n",
            "                 all          30          52       0.979       0.943       0.986       0.676\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     14/34     10.1G   0.03817  0.006226  0.001822   0.04622        45       640: 100% 32/32 [00:28<00:00,  1.11it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.66it/s]\n",
            "                 all          30          52       0.604         0.9       0.751       0.557\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     15/34     10.1G   0.03522  0.007006   0.00277   0.04499        55       640: 100% 32/32 [00:30<00:00,  1.05it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.76it/s]\n",
            "                 all          30          52       0.934       0.944       0.974       0.596\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     16/34     10.1G    0.0315  0.006512  0.001506   0.03952        27       640: 100% 32/32 [00:28<00:00,  1.11it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.69it/s]\n",
            "                 all          30          52           1       0.907        0.99       0.761\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     17/34     10.1G   0.02903  0.006102  0.001147   0.03628        44       640: 100% 32/32 [00:29<00:00,  1.09it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.62it/s]\n",
            "                 all          30          52           1       0.929       0.993       0.751\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     18/34     10.1G   0.02762  0.005646  0.001019   0.03428        40       640: 100% 32/32 [00:28<00:00,  1.12it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.96it/s]\n",
            "                 all          30          52        0.96       0.981       0.995       0.793\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     19/34     10.1G   0.02701   0.00562 0.0009971   0.03362        47       640: 100% 32/32 [00:29<00:00,  1.09it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.44it/s]\n",
            "                 all          30          52        0.98       0.873       0.991       0.798\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     20/34     10.1G   0.02541  0.005357 0.0009351    0.0317        42       640: 100% 32/32 [00:29<00:00,  1.08it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.68it/s]\n",
            "                 all          30          52       0.982       0.961       0.993       0.736\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     21/34     10.1G   0.02487  0.005261 0.0009737    0.0311        53       640: 100% 32/32 [00:29<00:00,  1.09it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.74it/s]\n",
            "                 all          30          52       0.944       0.981       0.989       0.773\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     22/34     10.1G   0.02229  0.005124 0.0008515   0.02827        52       640: 100% 32/32 [00:30<00:00,  1.06it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.79it/s]\n",
            "                 all          30          52       0.931       0.999       0.988       0.797\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     23/34     10.1G   0.02324  0.004867 0.0007271   0.02884        40       640: 100% 32/32 [00:28<00:00,  1.10it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.85it/s]\n",
            "                 all          30          52       0.981       0.969        0.99        0.78\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     24/34     10.1G   0.02226  0.005016 0.0007028   0.02798        51       640: 100% 32/32 [00:29<00:00,  1.10it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.78it/s]\n",
            "                 all          30          52       0.934       0.981       0.982       0.782\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     25/34     10.1G   0.02215  0.004888 0.0006975   0.02773        49       640: 100% 32/32 [00:29<00:00,  1.09it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.81it/s]\n",
            "                 all          30          52        0.96       0.981       0.983       0.775\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     26/34     10.1G   0.02041  0.004716 0.0005973   0.02572        57       640: 100% 32/32 [00:29<00:00,  1.10it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.85it/s]\n",
            "                 all          30          52       0.963       0.968       0.988       0.767\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     27/34     10.1G   0.01931  0.004595 0.0005148   0.02442        52       640: 100% 32/32 [00:28<00:00,  1.13it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.73it/s]\n",
            "                 all          30          52       0.981       0.946       0.988        0.78\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     28/34     10.1G   0.01833  0.004458  0.000466   0.02326        56       640: 100% 32/32 [00:28<00:00,  1.13it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.87it/s]\n",
            "                 all          30          52       0.963       0.973       0.992       0.803\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     29/34     10.1G   0.01777  0.004303 0.0004869   0.02256        42       640: 100% 32/32 [00:30<00:00,  1.04it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.55it/s]\n",
            "                 all          30          52       0.942       0.981       0.991       0.802\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     30/34     10.1G   0.01711  0.004246 0.0004666   0.02182        45       640: 100% 32/32 [00:29<00:00,  1.10it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.37it/s]\n",
            "                 all          30          52       0.931           1       0.993       0.796\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     31/34     10.1G   0.01739  0.004232 0.0004427   0.02206        43       640: 100% 32/32 [00:29<00:00,  1.08it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.72it/s]\n",
            "                 all          30          52           1       0.946       0.994       0.804\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     32/34     10.1G   0.01657  0.004169  0.000414   0.02115        41       640: 100% 32/32 [00:30<00:00,  1.06it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.74it/s]\n",
            "                 all          30          52       0.939           1       0.994       0.799\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     33/34     10.1G   0.01622  0.004163 0.0004073    0.0208        40       640: 100% 32/32 [00:29<00:00,  1.07it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.84it/s]\n",
            "                 all          30          52       0.945           1       0.992       0.805\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     34/34     10.1G   0.01533  0.003888 0.0003673   0.01958        38       640: 100% 32/32 [00:29<00:00,  1.08it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.91it/s]\n",
            "                 all          30          52       0.944           1       0.992       0.792\n",
            "                ball          30          25       0.888           1       0.988       0.762\n",
            "                hand          30          27           1           1       0.996       0.823\n",
            "35 epochs completed in 0.327 hours.\n",
            "\n",
            "Optimizer stripped from runs/train/250_img_AUG2/weights/last.pt, 74.8MB\n",
            "Optimizer stripped from runs/train/250_img_AUG2/weights/best.pt, 74.8MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing\n",
        "\n",
        "Test the mAP separately from the training process.\n",
        "1. Change the val folder in coco.yaml to data/test. The reason is that it always looks in the val folder to test. Change this before testing and then change it back to data/val. No automatic solution found.\n",
        "2. Change the confidence threshold and iou threshold to different instances. As the algorithm gets better, the conf thresholds are increased during time. The instances are: 0.001, 0.2, 0.5, 0.7 and 0.9. \n",
        "3. Run the test.py file with your custom weights. This will then show the mAP for the custom model.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zgfZDXOwz8TV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing with 50 images"
      ],
      "metadata": {
        "id": "uczClcx1hSyr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the normal model \n",
        "\n",
        "conf: 0.2\n",
        "\n",
        "\n",
        "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:02<00:00,  2.06s/it]\n",
        "                 all          30          53         0.5      0.0357      0.0382      0.0166\n",
        "                ball          30          28           1      0.0714      0.0764      0.0331\n",
        "                hand          30          25           0           0           0           0\n",
        "\n",
        "conf: 0.5\n",
        "\n",
        "\n",
        "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:01<00:00,  1.13s/it]\n",
        "                 all          30           0           0           0           0           0\n",
        "\n",
        "conf: 0.7\n",
        "\n",
        "\n",
        "\n",
        "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:01<00:00,  1.13s/it]\n",
        "                 all          30           0           0           0           0           0\n",
        "\n"
      ],
      "metadata": {
        "id": "G3TiROODJJAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py --weights runs/train/50_img/weights/last.pt --conf-thres 0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd4XOZC6HOoI",
        "outputId": "89840103-9a54-4552-f132-0958ce1b6405"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=32, conf_thres=0.2, data='data/coco.yaml', device='', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=True, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['runs/train/50_img/weights/last.pt'])\n",
            "YOLOR 🚀 2023-2-9 torch 1.13.1+cu116 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36487166 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'data/test.cache' images and labels... 30 found, 0 missing, 0 empty, 0 corrupted: 100% 30/30 [00:00<?, ?it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:01<00:00,  1.33s/it]\n",
            "                 all          30          53         0.5      0.0357      0.0382      0.0166\n",
            "                ball          30          28           1      0.0714      0.0764      0.0331\n",
            "                hand          30          25           0           0           0           0\n",
            "Speed: 17.3/1.8/19.1 ms inference/NMS/total per 640x640 image at batch-size 32\n",
            "\n",
            "Evaluating pycocotools mAP... saving runs/test/exp96/last_predictions.json...\n",
            "loading annotations into memory...\n",
            "pycocotools unable to run: [Errno 2] No such file or directory: './coco/annotations/instances_val2017.json'\n",
            "Results saved to runs/test/exp96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py --weights runs/train/50_img/weights/last.pt --conf-thres 0.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHCHkwEsF3Wj",
        "outputId": "87c7edf7-69d6-4a59-b6c4-c6b548793be2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=32, conf_thres=0.5, data='data/coco.yaml', device='', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=True, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['runs/train/50_img/weights/last.pt'])\n",
            "YOLOR 🚀 2023-2-9 torch 1.13.1+cu116 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36487166 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'data/test.cache' images and labels... 30 found, 0 missing, 0 empty, 0 corrupted: 100% 30/30 [00:00<?, ?it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.17it/s]\n",
            "                 all          30           0           0           0           0           0\n",
            "Speed: 11.6/0.1/11.7 ms inference/NMS/total per 640x640 image at batch-size 32\n",
            "/usr/local/lib/python3.8/dist-packages/seaborn/matrix.py:198: RuntimeWarning: All-NaN slice encountered\n",
            "  vmin = np.nanmin(calc_data)\n",
            "/usr/local/lib/python3.8/dist-packages/seaborn/matrix.py:203: RuntimeWarning: All-NaN slice encountered\n",
            "  vmax = np.nanmax(calc_data)\n",
            "Results saved to runs/test/exp97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py --weights runs/train/50_img/weights/last.pt --conf-thres 0.7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwekibkSGvJc",
        "outputId": "98b6a509-ade8-4692-be0f-fed0fd49320f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=32, conf_thres=0.7, data='data/coco.yaml', device='', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=True, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['runs/train/50_img/weights/last.pt'])\n",
            "YOLOR 🚀 2023-2-9 torch 1.13.1+cu116 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36487166 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'data/test.cache' images and labels... 30 found, 0 missing, 0 empty, 0 corrupted: 100% 30/30 [00:00<?, ?it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.23it/s]\n",
            "                 all          30           0           0           0           0           0\n",
            "Speed: 10.1/0.2/10.3 ms inference/NMS/total per 640x640 image at batch-size 32\n",
            "/usr/local/lib/python3.8/dist-packages/seaborn/matrix.py:198: RuntimeWarning: All-NaN slice encountered\n",
            "  vmin = np.nanmin(calc_data)\n",
            "/usr/local/lib/python3.8/dist-packages/seaborn/matrix.py:203: RuntimeWarning: All-NaN slice encountered\n",
            "  vmax = np.nanmax(calc_data)\n",
            "Results saved to runs/test/exp98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the augmented model\n",
        "\n",
        "\n",
        "conf : 0.2\n",
        "\n",
        "\n",
        "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:01<00:00,  1.13s/it]\n",
        "                 all          30          53       0.973       0.853       0.903       0.633\n",
        "                ball          30          28           1       0.986           1       0.716\n",
        "                hand          30          25       0.946        0.72       0.806       0.551\n",
        "\n",
        "conf: 0.5\n",
        "\n",
        "\n",
        "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.03it/s]\n",
        "                 all          30          53           1       0.502       0.507       0.373\n",
        "                ball          30          28           1       0.964       0.969       0.714\n",
        "                hand          30          25           1        0.04       0.045      0.0315\n",
        "\n",
        "conf: 0.7\n",
        "\n",
        "\n",
        "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.19it/s]\n",
        "                 all          30          53         0.5      0.0714      0.0739       0.056\n",
        "                ball          30          28           1       0.143       0.148       0.112\n",
        "                hand          30          25           0           0           0           0\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kHpc32hVaJsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py --weights runs/train/50_img_AUG/weights/best.pt --conf-thres 0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhY-Ws8tH2d0",
        "outputId": "bb1c43f4-91f9-4629-afb5-46b33bef6a0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=32, conf_thres=0.2, data='data/coco.yaml', device='', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=True, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['runs/train/50_img_AUG/weights/best.pt'])\n",
            "YOLOR 🚀 2023-2-9 torch 1.13.1+cu116 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36487166 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'data/test.cache' images and labels... 30 found, 0 missing, 0 empty, 0 corrupted: 100% 30/30 [00:00<?, ?it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:01<00:00,  1.03s/it]\n",
            "                 all          30          53       0.973       0.853       0.903       0.633\n",
            "                ball          30          28           1       0.986           1       0.716\n",
            "                hand          30          25       0.946        0.72       0.806       0.551\n",
            "Speed: 10.7/3.2/13.9 ms inference/NMS/total per 640x640 image at batch-size 32\n",
            "\n",
            "Evaluating pycocotools mAP... saving runs/test/exp101/best_predictions.json...\n",
            "loading annotations into memory...\n",
            "pycocotools unable to run: [Errno 2] No such file or directory: './coco/annotations/instances_val2017.json'\n",
            "Results saved to runs/test/exp101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py --weights runs/train/50_img_AUG/weights/best.pt --conf-thres 0.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhu0iUHWH2Iz",
        "outputId": "57a47385-e1b6-4170-b40b-1f0b26547ce7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=32, conf_thres=0.5, data='data/coco.yaml', device='', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=True, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['runs/train/50_img_AUG/weights/best.pt'])\n",
            "YOLOR 🚀 2023-2-9 torch 1.13.1+cu116 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36487166 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'data/test.cache' images and labels... 30 found, 0 missing, 0 empty, 0 corrupted: 100% 30/30 [00:00<?, ?it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.01it/s]\n",
            "                 all          30          53           1       0.502       0.507       0.373\n",
            "                ball          30          28           1       0.964       0.969       0.714\n",
            "                hand          30          25           1        0.04       0.045      0.0315\n",
            "Speed: 10.2/1.0/11.2 ms inference/NMS/total per 640x640 image at batch-size 32\n",
            "\n",
            "Evaluating pycocotools mAP... saving runs/test/exp102/best_predictions.json...\n",
            "loading annotations into memory...\n",
            "pycocotools unable to run: [Errno 2] No such file or directory: './coco/annotations/instances_val2017.json'\n",
            "Results saved to runs/test/exp102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py --weights runs/train/50_img_AUG/weights/best.pt --conf-thres 0.7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPb1N_ECaLQH",
        "outputId": "2a8e135d-5298-41bf-9e2a-236cbabdd1f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=32, conf_thres=0.7, data='data/coco.yaml', device='', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=True, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['runs/train/50_img_AUG/weights/best.pt'])\n",
            "YOLOR 🚀 2023-2-9 torch 1.13.1+cu116 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36487166 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'data/test.cache' images and labels... 30 found, 0 missing, 0 empty, 0 corrupted: 100% 30/30 [00:00<?, ?it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.19it/s]\n",
            "                 all          30          53         0.5      0.0714      0.0739       0.056\n",
            "                ball          30          28           1       0.143       0.148       0.112\n",
            "                hand          30          25           0           0           0           0\n",
            "Speed: 11.4/0.7/12.1 ms inference/NMS/total per 640x640 image at batch-size 32\n",
            "\n",
            "Evaluating pycocotools mAP... saving runs/test/exp103/best_predictions.json...\n",
            "loading annotations into memory...\n",
            "pycocotools unable to run: [Errno 2] No such file or directory: './coco/annotations/instances_val2017.json'\n",
            "Results saved to runs/test/exp103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing with 100 images"
      ],
      "metadata": {
        "id": "dqbk8aYMwQCE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the normal model\n",
        "\n",
        "\n",
        "conf: 0.2\n",
        "\n",
        "\n",
        "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:01<00:00,  1.03s/it]\n",
        "                 all          30          53       0.971       0.858       0.888       0.575\n",
        "                ball          30          28       0.943           1       0.998       0.653\n",
        "                hand          30          25           1       0.716       0.779       0.497\n",
        "\n",
        "\n",
        "conf: 0.5\n",
        "\n",
        "\n",
        "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.05it/s]\n",
        "                 all          30          53         0.5       0.464       0.467       0.315\n",
        "                ball          30          28           1       0.929       0.934        0.63\n",
        "                hand          30          25           0           0           0           0\n",
        "\n",
        "conf: 0.7\n",
        "\n",
        "\n",
        "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.26it/s]\n",
        "                 all          30          53         0.5      0.0179      0.0204      0.0163\n",
        "                ball          30          28           1      0.0357      0.0407      0.0326\n",
        "                hand          30          25           0           0           0           0\n",
        "\n"
      ],
      "metadata": {
        "id": "YI8ZRHY7wZxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py --weights runs/train/100_img/weights/best.pt --conf-thres 0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHyddG4EIIE7",
        "outputId": "0aa37efd-26fa-46b2-fc4d-78ab1161041b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=32, conf_thres=0.2, data='data/coco.yaml', device='', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=True, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['runs/train/100_img/weights/best.pt'])\n",
            "YOLOR 🚀 2023-2-9 torch 1.13.1+cu116 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36487166 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'data/test.cache' images and labels... 30 found, 0 missing, 0 empty, 0 corrupted: 100% 30/30 [00:00<?, ?it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:01<00:00,  1.80s/it]\n",
            "                 all          30          53       0.971       0.858       0.888       0.575\n",
            "                ball          30          28       0.943           1       0.998       0.653\n",
            "                hand          30          25           1       0.716       0.779       0.497\n",
            "Speed: 23.2/1.4/24.6 ms inference/NMS/total per 640x640 image at batch-size 32\n",
            "\n",
            "Evaluating pycocotools mAP... saving runs/test/exp106/best_predictions.json...\n",
            "loading annotations into memory...\n",
            "pycocotools unable to run: [Errno 2] No such file or directory: './coco/annotations/instances_val2017.json'\n",
            "Results saved to runs/test/exp106\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py --weights runs/train/100_img/weights/best.pt --conf-thres 0.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DVcPTUrIICm",
        "outputId": "53a50b7a-a303-4ded-ae36-adde260a51bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=32, conf_thres=0.5, data='data/coco.yaml', device='', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=True, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['runs/train/100_img/weights/best.pt'])\n",
            "YOLOR 🚀 2023-2-9 torch 1.13.1+cu116 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36487166 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'data/test.cache' images and labels... 30 found, 0 missing, 0 empty, 0 corrupted: 100% 30/30 [00:00<?, ?it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.06it/s]\n",
            "                 all          30          53         0.5       0.464       0.467       0.315\n",
            "                ball          30          28           1       0.929       0.934        0.63\n",
            "                hand          30          25           0           0           0           0\n",
            "Speed: 9.9/2.3/12.2 ms inference/NMS/total per 640x640 image at batch-size 32\n",
            "\n",
            "Evaluating pycocotools mAP... saving runs/test/exp107/best_predictions.json...\n",
            "loading annotations into memory...\n",
            "pycocotools unable to run: [Errno 2] No such file or directory: './coco/annotations/instances_val2017.json'\n",
            "Results saved to runs/test/exp107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py --weights runs/train/100_img/weights/best.pt --conf-thres 0.7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyW-m5paIHyy",
        "outputId": "21c3261d-dd31-4116-ca86-5fc4f51236da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=32, conf_thres=0.7, data='data/coco.yaml', device='', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=True, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['runs/train/100_img/weights/best.pt'])\n",
            "YOLOR 🚀 2023-2-9 torch 1.13.1+cu116 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36487166 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'data/test.cache' images and labels... 30 found, 0 missing, 0 empty, 0 corrupted: 100% 30/30 [00:00<?, ?it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.12it/s]\n",
            "                 all          30          53         0.5      0.0179      0.0204      0.0163\n",
            "                ball          30          28           1      0.0357      0.0407      0.0326\n",
            "                hand          30          25           0           0           0           0\n",
            "Speed: 13.0/0.3/13.3 ms inference/NMS/total per 640x640 image at batch-size 32\n",
            "\n",
            "Evaluating pycocotools mAP... saving runs/test/exp108/best_predictions.json...\n",
            "loading annotations into memory...\n",
            "pycocotools unable to run: [Errno 2] No such file or directory: './coco/annotations/instances_val2017.json'\n",
            "Results saved to runs/test/exp108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the augmented model.\n",
        "\n",
        "\n",
        "conf: 0.2\n",
        "\n",
        "\n",
        "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:01<00:00,  1.81s/it]\n",
        "                 all          30          53           1       0.975       0.998       0.776\n",
        "                ball          30          28           1       0.989           1       0.753\n",
        "                hand          30          25           1        0.96       0.997       0.798\n",
        "\n",
        "conf: 0.5\n",
        "\n",
        "\n",
        "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:01<00:00,  1.03s/it]\n",
        "                 all          30          53           1       0.924       0.929        0.74\n",
        "                ball          30          28           1       0.929       0.934       0.717\n",
        "                hand          30          25           1        0.92       0.925       0.763\n",
        "\n",
        "conf: 0.7\n",
        "\n",
        "\n",
        "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.05it/s]\n",
        "                 all          30          53           1       0.396       0.401       0.338\n",
        "                ball          30          28           1      0.0714      0.0764      0.0688\n",
        "                hand          30          25           1        0.72       0.725       0.608\n"
      ],
      "metadata": {
        "id": "kjEuFGsawe40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py --weights runs/train/100_img_AUG2/weights/best.pt --conf-thres 0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ue2wHqFyIROJ",
        "outputId": "233c917f-bc43-4e23-c7e2-f8a8777d4d20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=32, conf_thres=0.2, data='data/coco.yaml', device='', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=True, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['runs/train/100_img_AUG2/weights/best.pt'])\n",
            "YOLOR 🚀 2023-2-9 torch 1.13.1+cu116 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36487166 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'data/test.cache' images and labels... 30 found, 0 missing, 0 empty, 0 corrupted: 100% 30/30 [00:00<?, ?it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:01<00:00,  1.81s/it]\n",
            "                 all          30          53           1       0.975       0.998       0.776\n",
            "                ball          30          28           1       0.989           1       0.753\n",
            "                hand          30          25           1        0.96       0.997       0.798\n",
            "Speed: 16.9/2.5/19.4 ms inference/NMS/total per 640x640 image at batch-size 32\n",
            "\n",
            "Evaluating pycocotools mAP... saving runs/test/exp117/best_predictions.json...\n",
            "loading annotations into memory...\n",
            "pycocotools unable to run: [Errno 2] No such file or directory: './coco/annotations/instances_val2017.json'\n",
            "Results saved to runs/test/exp117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py --weights runs/train/100_img_AUG2/weights/best.pt --conf-thres 0.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wwl82w5OIRER",
        "outputId": "0c468c5c-e830-40e8-c5a0-a108b1322e23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=32, conf_thres=0.5, data='data/coco.yaml', device='', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=True, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['runs/train/100_img_AUG2/weights/best.pt'])\n",
            "YOLOR 🚀 2023-2-9 torch 1.13.1+cu116 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36487166 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'data/test.cache' images and labels... 30 found, 0 missing, 0 empty, 0 corrupted: 100% 30/30 [00:00<?, ?it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:01<00:00,  1.03s/it]\n",
            "                 all          30          53           1       0.924       0.929        0.74\n",
            "                ball          30          28           1       0.929       0.934       0.717\n",
            "                hand          30          25           1        0.92       0.925       0.763\n",
            "Speed: 10.0/3.6/13.6 ms inference/NMS/total per 640x640 image at batch-size 32\n",
            "\n",
            "Evaluating pycocotools mAP... saving runs/test/exp118/best_predictions.json...\n",
            "loading annotations into memory...\n",
            "pycocotools unable to run: [Errno 2] No such file or directory: './coco/annotations/instances_val2017.json'\n",
            "Results saved to runs/test/exp118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py --weights runs/train/100_img_AUG2/weights/best.pt --conf-thres 0.7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuwYIo5zIQ86",
        "outputId": "b952bfe5-268f-43b2-8aa0-badd8a94cc14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(weights=['runs/train/100_img_AUG2/weights/best.pt'], data='data/coco.yaml', batch_size=32, img_size=640, conf_thres=0.7, iou_thres=0.65, task='val', device='', single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=True, project='runs/test', name='exp', exist_ok=False, no_trace=False, v5_metric=False)\n",
            "YOLOR 🚀 2023-2-9 torch 2.0.0+cu118 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.9/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36487166 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'data/test' images and labels... 30 found, 0 missing, 0 empty, 0 corrupted: 100% 30/30 [00:50<00:00,  1.68s/it]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: data/test.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:01<00:00,  1.12s/it]\n",
            "                 all          30          53           1       0.396       0.401       0.338\n",
            "                ball          30          28           1      0.0714      0.0764      0.0688\n",
            "                hand          30          25           1        0.72       0.725       0.608\n",
            "Speed: 14.8/0.9/15.6 ms inference/NMS/total per 640x640 image at batch-size 32\n",
            "\n",
            "Evaluating pycocotools mAP... saving runs/test/exp2/best_predictions.json...\n",
            "loading annotations into memory...\n",
            "pycocotools unable to run: [Errno 2] No such file or directory: './coco/annotations/instances_val2017.json'\n",
            "Results saved to runs/test/exp2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing with 250 images"
      ],
      "metadata": {
        "id": "G4gCVCD3k0c5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the pretrained model\n",
        "\n",
        "\n",
        "conf: 0.2\n",
        "\n",
        "\n",
        "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:01<00:00,  1.03s/it]\n",
        "                 all          30          53           1           1           1       0.799\n",
        "                ball          30          28           1           1           1       0.789\n",
        "                hand          30          25           1           1       0.999       0.809\n",
        "\n",
        "conf: 0.5\n",
        "\n",
        "\n",
        "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:01<00:00,  1.08s/it]\n",
        "                 all          30          53           1           1           1       0.799\n",
        "                ball          30          28           1           1           1       0.789\n",
        "                hand          30          25           1           1           1        0.81\n",
        "\n",
        "conf: 0.7\n",
        "\n",
        "\n",
        "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:01<00:00,  1.00s/it]\n",
        "                 all          30          53           1       0.882       0.887       0.724\n",
        "                ball          30          28           1       0.964       0.969        0.78\n",
        "                hand          30          25           1         0.8       0.805       0.669\n",
        "\n"
      ],
      "metadata": {
        "id": "FXalcrJCq4Lc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py --weights runs/train/250_img/weights/best.pt --conf-thres 0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVpFSTl0k73e",
        "outputId": "a0b8c711-803b-4708-aad9-8512af6e91ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=32, conf_thres=0.2, data='data/coco.yaml', device='', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=True, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['runs/train/250_img/weights/best.pt'])\n",
            "YOLOR 🚀 2023-2-9 torch 1.13.1+cu116 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36487166 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'data/test.cache' images and labels... 30 found, 0 missing, 0 empty, 0 corrupted: 100% 30/30 [00:00<?, ?it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:01<00:00,  1.67s/it]\n",
            "                 all          30          53           1           1           1       0.799\n",
            "                ball          30          28           1           1           1       0.789\n",
            "                hand          30          25           1           1       0.999       0.809\n",
            "Speed: 13.8/2.7/16.5 ms inference/NMS/total per 640x640 image at batch-size 32\n",
            "\n",
            "Evaluating pycocotools mAP... saving runs/test/exp116/best_predictions.json...\n",
            "loading annotations into memory...\n",
            "pycocotools unable to run: [Errno 2] No such file or directory: './coco/annotations/instances_val2017.json'\n",
            "Results saved to runs/test/exp116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py --weights runs/train/250_img/weights/best.pt --conf-thres 0.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTyCejUrIa3d",
        "outputId": "b407bf3f-8256-40e4-9cff-64773635ea07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=32, conf_thres=0.5, data='data/coco.yaml', device='', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=True, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['runs/train/250_img/weights/best.pt'])\n",
            "YOLOR 🚀 2023-2-9 torch 1.13.1+cu116 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36487166 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'data/test.cache' images and labels... 30 found, 0 missing, 0 empty, 0 corrupted: 100% 30/30 [00:00<?, ?it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:01<00:00,  1.08s/it]\n",
            "                 all          30          53           1           1           1       0.799\n",
            "                ball          30          28           1           1           1       0.789\n",
            "                hand          30          25           1           1           1        0.81\n",
            "Speed: 10.3/1.4/11.7 ms inference/NMS/total per 640x640 image at batch-size 32\n",
            "\n",
            "Evaluating pycocotools mAP... saving runs/test/exp117/best_predictions.json...\n",
            "loading annotations into memory...\n",
            "pycocotools unable to run: [Errno 2] No such file or directory: './coco/annotations/instances_val2017.json'\n",
            "Results saved to runs/test/exp117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py --weights runs/train/250_img/weights/best.pt --conf-thres 0.7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBK68CwbIaqI",
        "outputId": "bbdae8f7-d0c6-4794-aae9-abd2aa63f123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=32, conf_thres=0.7, data='data/coco.yaml', device='', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=True, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['runs/train/250_img/weights/best.pt'])\n",
            "YOLOR 🚀 2023-2-9 torch 1.13.1+cu116 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36487166 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'data/test.cache' images and labels... 30 found, 0 missing, 0 empty, 0 corrupted: 100% 30/30 [00:00<?, ?it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.02it/s]\n",
            "                 all          30          53           1       0.882       0.887       0.724\n",
            "                ball          30          28           1       0.964       0.969        0.78\n",
            "                hand          30          25           1         0.8       0.805       0.669\n",
            "Speed: 9.3/1.2/10.5 ms inference/NMS/total per 640x640 image at batch-size 32\n",
            "\n",
            "Evaluating pycocotools mAP... saving runs/test/exp118/best_predictions.json...\n",
            "loading annotations into memory...\n",
            "pycocotools unable to run: [Errno 2] No such file or directory: './coco/annotations/instances_val2017.json'\n",
            "Results saved to runs/test/exp118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the augmented model\n",
        "\n",
        "\n",
        "conf: 0.2\n",
        "\n",
        "\n",
        "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:01<00:00,  1.05s/it]\n",
        "                 all          30          53           1           1           1       0.839\n",
        "                ball          30          28           1           1           1       0.816\n",
        "                hand          30          25           1           1           1       0.861\n",
        "\n",
        "conf: 0.5\n",
        "\n",
        "\n",
        "\n",
        "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:01<00:00,  1.05s/it]\n",
        "                 all          30          53           1           1           1       0.839\n",
        "                ball          30          28           1           1           1       0.816\n",
        "                hand          30          25           1           1           1       0.861\n",
        "\n",
        "conf: 0.7\n",
        "\n",
        "\n",
        "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:01<00:00,  1.08s/it]\n",
        "                 all          30          53           1       0.924       0.929       0.794\n",
        "                ball          30          28           1       0.929       0.934       0.776\n",
        "                hand          30          25           1        0.92       0.925       0.812\n"
      ],
      "metadata": {
        "id": "y14NYRMUrIyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py --weights runs/train/250_img_AUG2/weights/best.pt --conf-thres 0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3YsYxcyIgT4",
        "outputId": "128f212f-3044-4074-dbf3-e67da6952bcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=32, conf_thres=0.2, data='data/coco.yaml', device='', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=True, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['runs/train/250_img_AUG2/weights/best.pt'])\n",
            "YOLOR 🚀 2023-2-9 torch 1.13.1+cu116 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36487166 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'data/test.cache' images and labels... 30 found, 0 missing, 0 empty, 0 corrupted: 100% 30/30 [00:00<?, ?it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:01<00:00,  1.05s/it]\n",
            "                 all          30          53           1           1           1       0.839\n",
            "                ball          30          28           1           1           1       0.816\n",
            "                hand          30          25           1           1           1       0.861\n",
            "Speed: 10.7/3.1/13.8 ms inference/NMS/total per 640x640 image at batch-size 32\n",
            "\n",
            "Evaluating pycocotools mAP... saving runs/test/exp85/best_predictions.json...\n",
            "loading annotations into memory...\n",
            "pycocotools unable to run: [Errno 2] No such file or directory: './coco/annotations/instances_val2017.json'\n",
            "Results saved to runs/test/exp85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py --weights runs/train/250_img_AUG2/weights/best.pt --conf-thres 0.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBP7UillIgIP",
        "outputId": "262f6c5c-0c86-4888-b70a-4b96ffd53401"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=32, conf_thres=0.5, data='data/coco.yaml', device='', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=True, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['runs/train/250_img_AUG2/weights/best.pt'])\n",
            "YOLOR 🚀 2023-2-9 torch 1.13.1+cu116 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36487166 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'data/test.cache' images and labels... 30 found, 0 missing, 0 empty, 0 corrupted: 100% 30/30 [00:00<?, ?it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:01<00:00,  1.05s/it]\n",
            "                 all          30          53           1           1           1       0.839\n",
            "                ball          30          28           1           1           1       0.816\n",
            "                hand          30          25           1           1           1       0.861\n",
            "Speed: 10.7/2.2/13.0 ms inference/NMS/total per 640x640 image at batch-size 32\n",
            "\n",
            "Evaluating pycocotools mAP... saving runs/test/exp86/best_predictions.json...\n",
            "loading annotations into memory...\n",
            "pycocotools unable to run: [Errno 2] No such file or directory: './coco/annotations/instances_val2017.json'\n",
            "Results saved to runs/test/exp86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py --weights runs/train/250_img_AUG2/weights/best.pt --conf-thres 0.7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKuO9wZAIf9x",
        "outputId": "c467be39-ed55-4149-e34e-d22d14093da6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=32, conf_thres=0.7, data='data/coco.yaml', device='', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=True, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['runs/train/250_img_AUG2/weights/best.pt'])\n",
            "YOLOR 🚀 2023-2-9 torch 1.13.1+cu116 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36487166 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'data/test.cache' images and labels... 30 found, 0 missing, 0 empty, 0 corrupted: 100% 30/30 [00:00<?, ?it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:01<00:00,  1.08s/it]\n",
            "                 all          30          53           1       0.924       0.929       0.794\n",
            "                ball          30          28           1       0.929       0.934       0.776\n",
            "                hand          30          25           1        0.92       0.925       0.812\n",
            "Speed: 10.9/2.5/13.4 ms inference/NMS/total per 640x640 image at batch-size 32\n",
            "\n",
            "Evaluating pycocotools mAP... saving runs/test/exp87/best_predictions.json...\n",
            "loading annotations into memory...\n",
            "pycocotools unable to run: [Errno 2] No such file or directory: './coco/annotations/instances_val2017.json'\n",
            "Results saved to runs/test/exp87\n"
          ]
        }
      ]
    }
  ]
}